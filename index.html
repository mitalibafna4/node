<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>KK Wagh Engineering College</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="courses.html">Courses</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>
  </header>
  <main>
    <section id="home">
      <h2>Welcome to KK Wagh Engineering College</h2>
      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed vel felis orci. Fusce non ultricies metus, nec finibus felis. Nunc in enim sed erat rhoncus consequat. Mauris lacinia leo ac ultrices rutrum.</p>
      <p>Vestibulum vitae efficitur lorem. Suspendisse potenti. Quisque et ligula auctor, efficitur ligula sed, varius neque. Morbi varius semper dolor nec fringilla. Praesent porta eros vitae vulputate consectetur.</p>
    </section>
    <section id="about">
      <h2>About KK Wagh Engineering College</h2>
      <p>KK Wagh Engineering College is a renowned institution offering a wide range of engineering programs. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc cursus massa ut odio maximus consequat. Mauris tincidunt est in nunc vulputate malesuada. Phasellus ac fringilla metus.</p>
      <p>Donec eu est justo. Duis nec luctus tortor. Praesent convallis, tellus nec luctus semper, mi massa feugiat mauris, eget tincidunt erat neque sed enim. Pellentesque facilisis tellus velit, auctor ultricies lectus pellentesque et.</p>
    </section>
    <section id="courses">
      <h2>Courses Offered</h2>
      <ul>
        <li>Computer Science Engineering</li>
        <li>Mechanical Engineering</li>
        <li>Electrical Engineering</li>
        <li>Civil Engineering</li>
      </ul>
    </section>
    <section id="contact">
      <h2>Contact Us</h2>
      <p>KK Wagh Engineering College<br>
      Address: ABC Road, XYZ City<br>
      Phone: 123-456-7890<br>
      Email: info@kkwaghcollege.com</p>
    </section>
  </main>
  <footer>
    <p>&copy; 2023 KK Wagh Engineering College</p>
  </footer>
  <script src="script.js"></script>
</body>
</html>
<!--const express = require('express');
const app = express();
const path = require('path');

const PORT = 3000; // Change this to the desired port number

// Serve static files
app.use(express.static(path.join(__dirname, 'public')));

// Start the server
app.listen(PORT, () => {
  console.log(`Server is running on port ${PORT}`);
});-->

<!--
1)  sudo su hduser
2)  Password=student
3)  cd 
4)  cd /usr/local/hadoop
5)  start-dfs.sh
6)  start-yarn.sh(start yarn daemons & resource manager)
7)  jps(java processes)
8)  bin/hdfs dfs -mkdir /user786/
9)  bin/hdfs dfs -put /home/student/Desktop/data /user786/input
10) bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.0.jar wordcount /user786/input output786
11) bin/hdfs dfs -cat output786/*
12) stop-all.sh


Error dfNameNode is in safe mode , unable to to make directory :hadoop dfsadmin -safemode leave

=====================================================
sudo su hduser
pass
cd
ls
pwd
ls
sudo chown -R hduser analyzelogs/
cd analyzelogs/
ls
jar file dikhegi
pwd

sudo chmod +r "."
pwd

export wala statement

compile:
javac -d . Mapper
Reducer
driver

ls

cd SalesCountry

ls

cd ..

sudo gedit Manifest.txt

MainClass: Salescountry.salecoutrydriver

ls

jar -cfm analyzelogs.jar Manifest.txt SalesCCountry/*.class

jar -cfm analyzelogs.jar Manifest.txt SalesCountry/*.class


startdfs
yarn
jps
cd analyzelogs

sudo mkdir ~/input2000
sudo cp access_log_short.csv ~/input2000

sudo mkdir ~/input2000
sudo cp access_short.csv ~/input2000
$HADOOP_HOME/bin/hdfs -put ~/input2000 /
$HADOOP_HOME/bin/hdfs jar analyzelogs.jar /input2000 /output2000

$HADOOP_HOME/bin/hdfs -cat /output2000/port-00000

====================================================================
sudo su hduser
pass
start-dfs.sh
start-yarn.sh
jps
cs /usr/local/hive/bin
./hive

CREATE TABLE flightinfo (
  fname STRING,
  flight_number INT,
  departure_city STRING,
  destination_city STRING,
  flight_datetime TIMESTAMP
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ' '
STORED AS TEXTFILE;

load data local inpath '.txt' into table flightinfo;

insert into table flightinfo new values('s',)

select * from flightinfo;

desc flightinfo;

Clustered by (id) into 2 buckets stored as orc

create table schedule(sid int, sname string, dat timestamp) row format deliminited fields terminated by ',' stored as textfile;

> select fname,fnumber,dcity,decity,dtime,dept from flightinfo f join schedule s
on(scheduleid=s.scheduleid);

SELECT s.sname,COUNT(*) AS num_flights FROM flightinfo f JOIN schedule s ON
scheduleid=s.scheduleid GROUP BY s.sname;

> CREATE INDEX idx ON TABLE schedule(dat) AS
'org.apache.hadoop.hive.ql.index.compact.CompactIndexHandler' WITH DEFERRED REBUILD;

 select avg(dtime) from flightinfo;

SELECT flight_date, AVG(departure_delay) AS average_departure_delay
FROM flight_information
WHERE YEAR(flight_date) = 2008
GROUP BY flight_date;

sudo su hduser
pass
cd
ls
pwd
ls
sudo chown -R hduser analyzelogs/
cd analyzelogs/
ls
jar file dikhegi
pwd

sudo chmod +r "."
pwd

export wala statement

compile:
javac -d . Mapper
Reducer
driver

ls

cd SalesCountry

ls

cd ..

sudo gedit Manifest.txt

MainClass: Salescountry.salecoutrydriver

ls

jar -cfm analyzelogs.jar Manifest.txt SalesCCountry/*.class

jar -cfm analyzelogs.jar Manifest.txt SalesCountry/*.class


startdfs
yarn
jps
cd analyzelogs

sudo mkdir ~/input2000
sudo cp access_log_short.csv ~/input2000

sudo mkdir ~/input2000
sudo cp access_short.csv ~/input2000
$HADOOP_HOME/bin/hdfs -put ~/input2000 /
$HADOOP_HOME/bin/hdfs jar analyzelogs.jar /input2000 /output2000

$HADOOP_HOME/bin/hdfs -cat /output2000/port-00000

1)  sudo su hduser
2)  Password=student
3)  cd 
4)  cd /usr/local/hadoop
5)  start-dfs.sh
6)  start-yarn.sh(start yarn daemons & resource manager)
7)  jps(java processes)
8)  bin/hdfs dfs -mkdir /user786/
9)  bin/hdfs dfs -put /home/student/Desktop/data /user786/input
10) bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.0.jar wordcount /user786/input output786
11) bin/hdfs dfs -cat output786/*
12) stop-all.sh


Error dfNameNode is in safe mode , unable to to make directory :hadoop dfsadmin -safemode leave

=========================================================================
import requests
import bs4
request1 = requests.get('https://www.flipkart.com/redmi-10-midnight-black-64-gb/p/itmd93641e4ebb47?pid=MOBGC9GYEBH3GZ4E&lid=LSTMOBGC9GYEBH3GZ4E44YY0L&marketplace=FLIPKART&fm=productRecommendation%2Fsimilar&iid=R%3As%3Bp%3AMOBG73E7GKQK4KZP%3Bpt%3App%3Buid%3Aac8a3859-f4de-11ed-aa73-955faf22b2d0%3B.MOBGC9GYEBH3GZ4E&ppt=pp&ppn=pp&ssid=smh40m1g000000001684347262906&otracker=pp_reco_Similar%2BProducts_3_35.productCard.PMU_HORIZONTAL_REDMI%2B10%2B%2528Midnight%2BBlack%252C%2B64%2BGB%2529_MOBGC9GYEBH3GZ4E_productRecommendation%2Fsimilar_2&otracker1=pp_reco_PINNED_productRecommendation%2Fsimilar_Similar%2BProducts_GRID_productCard_cc_3_NA_view-all&cid=MOBGC9GYEBH3GZ4E')
request1
request1.content 
soup = bs4.BeautifulSoup(request1.text)
soup
#Fetching Reviews/Comments
reviews = soup.find_all('div',{'class' : 't-ZTKy'});
for review in reviews:
  print(review.get_text() + "\n\n")


#Average Overall rating
ratings = soup.find('div',{'class':'_3LWZlK'}).get_text();
print(ratings)

#Individual ratings
individual_ratings = soup.findAll('div',{'class':'_3LWZlK _1BLPMq'});
for indi_rating in individual_ratings:
  print(indi_rating.get_text() + " \n")

#Fetching tags
tags = soup.find('span',{'class':'yhB1nd GXgmTe'}).get_text();
tags

#Fetching Customer Names
customer_name = soup.findAll('p',{'class':'_2sc7ZR _2V5EHH'});
for cust_name in customer_name:
  print(cust_name.get_text() + " \n")

#create data
data = [["1", "Good phone in this price range, battery backup good, camera ok ok, and performance very very good ðŸ”¥ I am mi love And very fast delivery Flipkart, thanks", 5, "just here", "Rupam Dhara" ],
        [], 
        ["2", "Very nice mobile ðŸ¥³ðŸ˜ŠPerformance is very good ðŸ˜ŠCamera quality good ðŸ˜ŠGood zooming colour boost âœ¨I love itðŸ˜˜Thank you Flipkart ðŸ˜‡âœ¨", 4, "just here", "Soumadip Mondal" ],
        [],
        ["3", "Good phone very nice working and good performance nice look", 5, "just here", "Kuldeep Singh" ],
        [],
        ["4", "Mobile is best in this price rangeProcessor Qualcomm Snapdragon 680 is really powerful for multitasking and gamingCamera ðŸ“· Night mode is amazing ðŸ¤©Battery life is outstanding fabulous performanceReal 6000 MahOverall excellent performance5 star for Flipkart services", 5, "just here", "Rahul Dhochak" ],
        [],
        ["5", "Mobile is best in this price rangeProcessor Qualcomm Snapdragon 680 is really powerful for multitasking and gamingCamera ðŸ“· Night mode is amazing ðŸ¤©Battery life is outstanding fabulous performanceReal 6000 MahOverall excellent performance5 star for Flipkart services", 4, "just here", "Nilesh  Gaidhani" ],]
  
#define header names
col_names = ["Sr.No.", "Reviews/Comments", "Rating", "Tags", "Customer Name"]
  
#display table
from tabulate import tabulate
print(tabulate(data, headers=col_names))


-->
<!---->
